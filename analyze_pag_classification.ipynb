{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import models",
   "id": "c28e88db90983064"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:02.491338Z",
     "start_time": "2025-04-05T17:40:56.805384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lightning import LightningModule\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from config import get_config, SentenceClassificationConfig, LLMPagConfig\n",
    "from pag_classification.baseline_model import BaselineClassifier\n",
    "from pag_classification.embeddings_datamodule import SentenceEmbeddingsDataModule\n",
    "from pag_classification.evaluation_metrics import evaluate_robustness, accuracy_fgsm\n",
    "from pag_classification.pag_identity_model import PagIdentityClassifier\n",
    "from pag_classification.pag_score_model import PagScoreSimilarSamplesClassifier, PagScoreSimilarFeaturesClassifier"
   ],
   "id": "50b02ef46e75d511",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:02.498807Z",
     "start_time": "2025-04-05T17:41:02.495727Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "7f68cdeee9490d1f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:02.919094Z",
     "start_time": "2025-04-05T17:41:02.606449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_pag_config: LLMPagConfig = get_config('base')\n",
    "sentence_classification_pag_config: SentenceClassificationConfig = get_config('sentence_classification')"
   ],
   "id": "3dbf5d0a3eb318aa",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:05.052249Z",
     "start_time": "2025-04-05T17:41:02.925917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentences_datamodule = SentenceEmbeddingsDataModule(sentence_classification_pag_config)\n",
    "sentences_datamodule.prepare_data()\n",
    "sentences_datamodule.setup()\n",
    "train_dataset, test_dataset = sentences_datamodule.train_dataset, sentences_datamodule.test_dataset"
   ],
   "id": "c3a6316b565cf1d4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:05.064232Z",
     "start_time": "2025-04-05T17:41:05.060755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_classifiers = []\n",
    "\n",
    "\n",
    "def instantiate_trained_classifier(classifier_name: str, clazz, **kwargs) -> BaselineClassifier:\n",
    "    ckpt_dir = sentence_classification_pag_config.output_dir / f'training_{classifier_name}'\n",
    "    ckpt_file = max((\n",
    "        f\n",
    "        for f in ckpt_dir.iterdir()\n",
    "        if f.name.startswith(classifier_name) and f.name.endswith('.ckpt')\n",
    "    ), key=lambda f: f.stat().st_ctime)\n",
    "    print('Loading from checkpoint:', ckpt_file)\n",
    "\n",
    "    trained_classifier = clazz.load_from_checkpoint(ckpt_file, cfg=sentence_classification_pag_config, **kwargs)\n",
    "    trained_classifier.to(device)\n",
    "    trained_classifier.eval()\n",
    "\n",
    "    all_classifiers.append((classifier_name, trained_classifier))\n",
    "    return trained_classifier"
   ],
   "id": "4abcf12b03e61d2d",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:05.166794Z",
     "start_time": "2025-04-05T17:41:05.103853Z"
    }
   },
   "cell_type": "code",
   "source": "instantiate_trained_classifier('baseline', BaselineClassifier)",
   "id": "cdc50a03ab345698",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: checkpoints/sentence-classification/training_baseline/baseline.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineClassifier(\n",
       "  (classifier): EmbeddingClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:06.121427Z",
     "start_time": "2025-04-05T17:41:05.232305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instantiate_trained_classifier('pag-score-similar-samples', PagScoreSimilarSamplesClassifier,\n",
    "                               train_dataset=train_dataset)"
   ],
   "id": "5201c8dac50a1627",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: checkpoints/sentence-classification/training_pag-score-similar-samples/pag-score-similar-samples.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PagScoreSimilarSamplesClassifier(\n",
       "  (classifier): EmbeddingClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:07.151493Z",
     "start_time": "2025-04-05T17:41:06.131479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instantiate_trained_classifier('pag-score-similar-features', PagScoreSimilarFeaturesClassifier,\n",
    "                               train_dataset=train_dataset)"
   ],
   "id": "ea7014fe3269a5e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: checkpoints/sentence-classification/training_pag-score-similar-features/pag-score-similar-features-v1.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PagScoreSimilarFeaturesClassifier(\n",
       "  (classifier): EmbeddingClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:07.226790Z",
     "start_time": "2025-04-05T17:41:07.172470Z"
    }
   },
   "cell_type": "code",
   "source": "instantiate_trained_classifier('pag-identity', PagIdentityClassifier)",
   "id": "fda61617b966e4de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: checkpoints/sentence-classification/training_pag-identity/pag-identity.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PagIdentityClassifier(\n",
       "  (classifier): EmbeddingClassifier(\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=128, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T17:41:07.306195Z",
     "start_time": "2025-04-05T17:41:07.303135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('Trained classifiers:')\n",
    "for name, classifier in all_classifiers:\n",
    "    print(f'  {name}: {classifier.__class__.__name__}')"
   ],
   "id": "5b3a3fb92c5895a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained classifiers:\n",
      "  baseline: BaselineClassifier\n",
      "  pag-score-similar-samples: PagScoreSimilarSamplesClassifier\n",
      "  pag-score-similar-features: PagScoreSimilarFeaturesClassifier\n",
      "  pag-identity: PagIdentityClassifier\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Robustness evaluation",
   "id": "1bb4e277cc8b585b"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-05T17:41:07.416135Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for name, classifier in all_classifiers:\n",
    "    robustness = evaluate_robustness(classifier, test_dataset, attack_name='apgd-ce')\n",
    "    print(f'[{name}] [APGD-CE] Robustness: {robustness:.1%}')"
   ],
   "id": "2422963b2061ceaf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 37/61 [00:55<00:46,  1.95s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, classifier in all_classifiers:\n",
    "    robustness = evaluate_robustness(classifier, test_dataset, attack_name='apgd-ce', eps=0.5)\n",
    "    print(f'[{name}] [APGD-CE, eps=0.5] Robustness: {robustness:.1%}')"
   ],
   "id": "8793c64c1ef6ebd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "attack_name = 'square'\n",
    "max_batches = 10\n",
    "\n",
    "for name, classifier in all_classifiers:\n",
    "    robustness = evaluate_robustness(classifier, test_dataset, attack_name=attack_name, max_batches=max_batches)\n",
    "    print(f'[{name}] [{attack_name}] Robustness: {robustness:.1%}')"
   ],
   "id": "f4b3d9e5316ccfcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_fgsm_accuracies = dict()\n",
    "\n",
    "for alpha in tqdm(torch.arange(1e-8, 5e-2, 5e-4)):\n",
    "    all_fgsm_accuracies[alpha] = dict()\n",
    "\n",
    "    for name, classifier in all_classifiers:\n",
    "        classifier.to(device)\n",
    "\n",
    "        real_accuracy, adv_accuracy = accuracy_fgsm(\n",
    "            model=classifier,\n",
    "            dataset=test_dataset,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "\n",
    "        all_fgsm_accuracies[alpha][name] = {\n",
    "            'real_accuracy': real_accuracy,\n",
    "            'adversarial_accuracy': adv_accuracy,\n",
    "        }"
   ],
   "id": "31d0a541b7d019d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for alpha in [1e-3, 5e-3, 1e-2]:\n",
    "    print(f'FGSM with {alpha=}:')\n",
    "    for name, classifier in all_classifiers:\n",
    "        _, adv_accuracy = accuracy_fgsm(\n",
    "            model=classifier,\n",
    "            dataset=test_dataset,\n",
    "            alpha=alpha,\n",
    "        )\n",
    "        print(f'  [{name}] Adversarial accuracy: {adv_accuracy:.1%}')\n",
    "    print()"
   ],
   "id": "845014350c6bb9d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown', 'pink', 'gray'][:len(all_classifiers)]\n",
    "\n",
    "x = list(all_fgsm_accuracies.keys())\n",
    "\n",
    "for (name, _), color in zip(all_classifiers, colors):\n",
    "    y = [\n",
    "        fgsm_entry[name]['adversarial_accuracy'] for fgsm_entry in all_fgsm_accuracies.values()\n",
    "    ]\n",
    "\n",
    "    plt.plot(\n",
    "        x, y,\n",
    "        label=name,\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().ticklabel_format(axis='x', style='sci', scilimits=(0, 0))\n",
    "plt.xlabel('Alpha perturbation in FSGM')\n",
    "plt.ylabel('Accuracy');"
   ],
   "id": "2c892470cda2e00f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot of internals",
   "id": "f2fdc8cb8cbe9ffd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def show_logits(dataset, target_classifier: LightningModule, title: str = None, n: int = 4096, ax=None):\n",
    "    dataloader = DataLoader(dataset, batch_size=n, shuffle=True)\n",
    "    batch = next(iter(dataloader))\n",
    "    embeddings, labels = batch['embedding'].to(device), batch['label'].cpu()\n",
    "\n",
    "    hidden_state = embeddings\n",
    "    for layer in target_classifier.classifier.classifier:\n",
    "        hidden_state = layer(hidden_state)\n",
    "    projected_points = hidden_state.cpu()\n",
    "\n",
    "    true_points = projected_points[labels == 1]\n",
    "    false_points = projected_points[labels == 0]\n",
    "\n",
    "    if ax is None:\n",
    "        ax = plt\n",
    "    ax.scatter(true_points[:, 0], true_points[:, 1], label='True', color='green', alpha=.05)\n",
    "    ax.scatter(false_points[:, 0], false_points[:, 1], label='False', color='red', alpha=.05)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ],
   "id": "e39d56643ff08f9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, len(all_classifiers), figsize=(20, 5))\n",
    "for i, (name, classifier) in enumerate(all_classifiers):\n",
    "    show_logits(\n",
    "        dataset=test_dataset,\n",
    "        target_classifier=classifier,\n",
    "        title=name,\n",
    "        ax=axes[i],\n",
    "    )"
   ],
   "id": "8f33b0abea1cf2d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_inner_hidden_state(dataset, target_classifier: LightningModule, after_layer_idx: int, title: str = None,\n",
    "                            n: int = 4096, ax=plt):\n",
    "    target_classifier.eval()\n",
    "    layer = target_classifier.classifier.classifier[after_layer_idx]\n",
    "    print('Considering right after layer', layer)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=n, shuffle=True)\n",
    "    batch = next(iter(dataloader))\n",
    "    embeddings, labels = batch['embedding'].to(device), batch['label'].cpu()\n",
    "\n",
    "    hidden_state = embeddings\n",
    "    for layer in target_classifier.classifier.classifier[:after_layer_idx + 1]:\n",
    "        hidden_state = layer(hidden_state)\n",
    "    projected_points = hidden_state.cpu().numpy()\n",
    "\n",
    "    if projected_points.shape[1] > 2:\n",
    "        # Must apply tSNE\n",
    "        tsne = TSNE(n_components=2, random_state=1)\n",
    "        projected_points = tsne.fit_transform(projected_points)\n",
    "\n",
    "    true_points = projected_points[labels == 1]\n",
    "    false_points = projected_points[labels == 0]\n",
    "\n",
    "    assert projected_points.shape[1] == 2, \\\n",
    "        f'Points are {projected_points.shape[1]}-dimensional'\n",
    "    ax.scatter(true_points[:, 0], true_points[:, 1], label='True', color='blue', alpha=.05)\n",
    "    ax.scatter(false_points[:, 0], false_points[:, 1], label='False', color='red', alpha=.05)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.legend()"
   ],
   "id": "cd44c07cf609da80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, len(all_classifiers), figsize=(20, 5))\n",
    "for i, (name, classifier) in enumerate(all_classifiers):\n",
    "    show_inner_hidden_state(\n",
    "        dataset=test_dataset,\n",
    "        target_classifier=classifier,\n",
    "        after_layer_idx=-1,\n",
    "        title=name,\n",
    "        ax=axes[i],\n",
    "    )"
   ],
   "id": "10abcccfd88c888e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_layer_weights(target_classifier: LightningModule, layer_idx: int, title: str = None, ax=plt):\n",
    "    target_classifier.eval()\n",
    "    layer = target_classifier.classifier.classifier[layer_idx]\n",
    "    print('Considering weights of layer', layer)\n",
    "\n",
    "    if 'weight' not in dir(layer) or layer.weight.data.ndim != 2:\n",
    "        print('This may not be the layer you want.')\n",
    "        print(classifier)\n",
    "        return\n",
    "\n",
    "    weight_vectors = layer.weight.data  # + layer.bias.data.unsqueeze(1)\n",
    "    # weight_vectors = weight_vectors.t()\n",
    "    print('Showing matrix with shape:', weight_vectors.shape)\n",
    "\n",
    "    projected_points = weight_vectors.cpu().numpy()\n",
    "    if projected_points.shape[1] > 2:\n",
    "        # Must reduce dimensionality\n",
    "        tsne = TSNE(n_components=2, random_state=1)\n",
    "        projected_points = tsne.fit_transform(projected_points)\n",
    "\n",
    "    assert projected_points.shape[1] == 2, \\\n",
    "        f'Points are {projected_points.shape[1]}-dimensional'\n",
    "    ax.scatter(projected_points[:, 0], projected_points[:, 1])\n",
    "\n",
    "    ax.set_title(title)"
   ],
   "id": "ec3443340483be6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, len(all_classifiers), figsize=(20, 5))\n",
    "for i, (name, classifier) in enumerate(all_classifiers):\n",
    "    show_layer_weights(\n",
    "        target_classifier=classifier,\n",
    "        layer_idx=-4,\n",
    "        title=name,\n",
    "        ax=axes[i],\n",
    "    )"
   ],
   "id": "1147c8342708aca9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
