from dataclasses import dataclass
from typing import Any

import torch
from tqdm import tqdm

import gcg_utils
from data.data_processor import TextDataset
from gcg import FasterGCG
from models.base_model import BaseLMModel


@dataclass
class GCGResult:
    """
    Class to store the results of a GCG attack, for later analysis.
    """

    """
    Original prefix IDs, which are the first few tokens of the input text.
    """
    original_prefix_ids: list[int]

    """
    Target response IDs, which are the tokens we want to have as a completion.
    """
    target_response_ids: list[int]

    """
    Attack input string, which is the string generated by the GCG algorithm.
    """
    x_attack_str: str

    """
    Attack response IDs, which are the tokens generated by the LLM given the attack input string.
    """
    y_attack_response_ids: list[int]

    """
    Number of steps taken to generate the attack input string.
    """
    steps: int

    def to_dict(self) -> dict[str, Any]:
        """
        Convert the GCGResult object to a dictionary for easy serialization.
        """
        return {
            'original_prefix_ids': self.original_prefix_ids,
            'target_response_ids': self.target_response_ids,
            'x_attack_str': self.x_attack_str,
            'y_attack_response_ids': self.y_attack_response_ids,
            'steps': self.steps,
        }

    @staticmethod
    def from_dict(data: dict[str, Any]) -> 'GCGResult':
        """
        Create a GCGResult object from a dictionary.
        """
        return GCGResult(
            original_prefix_ids=data['original_prefix_ids'],
            target_response_ids=data['target_response_ids'],
            x_attack_str=data['x_attack_str'],
            y_attack_response_ids=data['y_attack_response_ids'],
            steps=data['steps'],
        )

    def get_success_tokens(self) -> int:
        return sum(
            1
            for target_token, attack_response_token in zip(self.target_response_ids, self.y_attack_response_ids)
            if target_token == attack_response_token
        )


def evaluate_model_with_gcg(gcg: FasterGCG,
                            lightning_module: BaseLMModel,
                            dataset: TextDataset,
                            target_response_len: int,
                            random_select_samples: bool = True,
                            max_samples_to_attack: int | None = None) -> list[GCGResult]:
    """
    Run GCG evaluation on the dataset.

    Args:
        gcg: GCG object
        lightning_module: Lightning module containing the target model and tokenizer to use in the attack
        dataset: Dataset to evaluate on
        target_response_len: Length of the target attack response we want to generate
        random_select_samples: Whether to randomly select samples from the dataset or not
        max_samples_to_attack: Maximum number of samples to attack. If None, all samples will be attacked.

    Returns:
        attack_success: Number of successful attacks
        attacks_total: Total number of attacks attempted
        steps_run: Total number of steps run for the successful attacks
    """
    gcg_utils.set_seeds()
    prefix_len = gcg.adversarial_tokens_length
    model, tokenizer = lightning_module.model, lightning_module.tokenizer

    max_samples_to_attack = len(dataset) if max_samples_to_attack is None else max_samples_to_attack
    max_samples_to_attack = min(max_samples_to_attack, len(dataset))

    samples_to_attack = torch.randperm(len(dataset))[:max_samples_to_attack].tolist() \
        if random_select_samples \
        else list(range(max_samples_to_attack))

    attacks: list[GCGResult] = []

    # Iterate through the dataset and attack each example
    for sample_idx in tqdm(samples_to_attack, desc="Evaluating with GCG"):
        item = dataset[sample_idx]
        input_ids = item.input_ids[item.attention_mask == 1]
        if input_ids.size(-1) <= prefix_len + target_response_len:
            # Skip if the target response is too short
            continue

        # Split into prefix and target response
        original_prefix_ids = input_ids[:prefix_len]
        # original_prefix_str = gcg_utils.tokenizer.decode(original_prefix_ids)
        target_response_ids = input_ids[prefix_len:prefix_len + target_response_len]
        target_response_str = tokenizer.decode(target_response_ids)

        # Run the attack
        x_attack_str, y_response_str, steps = gcg.tokenize_and_attack(tokenizer, model, None, target_response_str)
        # noinspection PyTypeChecker
        y_response_ids: torch.Tensor = tokenizer.encode(y_response_str, return_tensors='pt')

        attacks.append(GCGResult(
            original_prefix_ids=original_prefix_ids.detach().cpu().tolist(),
            target_response_ids=target_response_ids.detach().cpu().tolist(),
            x_attack_str=x_attack_str,
            y_attack_response_ids=y_response_ids.detach().cpu().tolist(),
            steps=steps,
        ))

    return attacks
